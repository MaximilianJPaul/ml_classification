{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5be09ef",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9c3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09b274b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_labels = {\n",
    "    \"other\": 0,\n",
    "    \"comcuc\": 1,\n",
    "    \"cowpig1\": 2,\n",
    "    \"eucdov\": 3,\n",
    "    \"eueowl1\": 4,\n",
    "    \"grswoo\": 5,\n",
    "    \"tawowl1\": 6\n",
    "}\n",
    "\n",
    "birds = [bird for bird in list(birds_labels.keys()) if bird != \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cea06ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_rows(matrix):\n",
    "    indexes = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        if np.unique(row).size == 1:\n",
    "            indexes.append(i)\n",
    "            labels.append(np.unique(row)[0])\n",
    "    \n",
    "    indexes = np.array(indexes)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return indexes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79777b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(bird):\n",
    "    labels = []\n",
    "    features = []\n",
    "    bird_id = birds_labels[bird]\n",
    "    \n",
    "    path = f'./data/{bird}/'\n",
    "    labels_files = glob.glob(path + '*labels.npy')\n",
    "    counter = None\n",
    "    \n",
    "    for i, file in enumerate(labels_files):\n",
    "        print(f'{bird}: {i + 1}/{len(labels_files)}', end='\\r')\n",
    "        counter = i\n",
    "        data_id = path + ''.join(file.split(\".labels.npy\")).split('/')[-1] + '.npy'\n",
    "        \n",
    "        annotations = np.load(file)\n",
    "        feature = np.load(data_id)\n",
    "        \n",
    "        ind, label = unique_rows(annotations)\n",
    "        \n",
    "        if len(ind) == 0:\n",
    "            continue\n",
    "        \n",
    "        labels.append(label)\n",
    "        features.append(feature[ind])\n",
    "\n",
    "    print('\\n')\n",
    "    labels = np.concatenate(labels)\n",
    "    features = np.concatenate(features)\n",
    "    \n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5f1f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comcuc: 200/200\n",
      "\n",
      "cowpig1: 200/200\n",
      "\n",
      "eucdov: 200/200\n",
      "\n",
      "eueowl1: 200/200\n",
      "\n",
      "grswoo: 200/200\n",
      "\n",
      "tawowl1: 200/200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for bird in birds:\n",
    "    labels, features = load_data(bird)\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "    \n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5f4cf",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "509d9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler to make the data non-negative\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# # Perform feature selection\n",
    "# k_best_selector = SelectKBest(chi2, k=128)  # Select 2 best features\n",
    "# X_selected = k_best_selector.fit_transform(X, y)\n",
    "\n",
    "# # Print the selected features\n",
    "# selected_feature_indices = k_best_selector.get_support(indices=True)\n",
    "# # selected_feature_names = [data.feature_names[i] for i in selected_feature_indices]\n",
    "# # print(\"Selected Features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5f38643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85500, 548)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed54b0d",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de0eaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(17408, 1024)  # Updated input dimension\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 7)  # 7 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (N, 548) -> (N, 1, 548)\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # conv1 + ReLU + max pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # conv2 + ReLU + max pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # conv3 + ReLU + max pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))  # fc1 + ReLU\n",
    "        x = F.relu(self.fc2(x))  # fc2 + ReLU\n",
    "        x = self.fc3(x)  # fc3\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f68d0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d1190b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Epoch 1/500, Loss: 0.84302, Accuracy: 0.79889\n",
      "Epoch 2/500, Loss: 0.53024, Accuracy: 0.85099\n",
      "Epoch 3/500, Loss: 0.40865, Accuracy: 0.87181\n",
      "Epoch 4/500, Loss: 0.34133, Accuracy: 0.88409\n",
      "Epoch 5/500, Loss: 0.29741, Accuracy: 0.90152\n",
      "Epoch 6/500, Loss: 0.26643, Accuracy: 0.91029\n",
      "Epoch 7/500, Loss: 0.24423, Accuracy: 0.91947\n",
      "Epoch 8/500, Loss: 0.22570, Accuracy: 0.92415\n",
      "Epoch 9/500, Loss: 0.21126, Accuracy: 0.92778\n",
      "Epoch 10/500, Loss: 0.20021, Accuracy: 0.93193\n",
      "Epoch 11/500, Loss: 0.19128, Accuracy: 0.93444\n",
      "Epoch 12/500, Loss: 0.18359, Accuracy: 0.93298\n",
      "Epoch 13/500, Loss: 0.17677, Accuracy: 0.93848\n",
      "Epoch 14/500, Loss: 0.17009, Accuracy: 0.94146\n",
      "Epoch 15/500, Loss: 0.16479, Accuracy: 0.94333\n",
      "Epoch 16/500, Loss: 0.16010, Accuracy: 0.94158\n",
      "Epoch 17/500, Loss: 0.15591, Accuracy: 0.94427\n",
      "Epoch 18/500, Loss: 0.15073, Accuracy: 0.94743\n",
      "Epoch 19/500, Loss: 0.14724, Accuracy: 0.94737\n",
      "Epoch 20/500, Loss: 0.14471, Accuracy: 0.94836\n",
      "Epoch 21/500, Loss: 0.14107, Accuracy: 0.95129\n",
      "Epoch 22/500, Loss: 0.13722, Accuracy: 0.95310\n",
      "Epoch 23/500, Loss: 0.13498, Accuracy: 0.95129\n",
      "Epoch 24/500, Loss: 0.13167, Accuracy: 0.95491\n",
      "Epoch 25/500, Loss: 0.12902, Accuracy: 0.95526\n",
      "Epoch 26/500, Loss: 0.12623, Accuracy: 0.95485\n",
      "Epoch 27/500, Loss: 0.12398, Accuracy: 0.95503\n",
      "Epoch 28/500, Loss: 0.12209, Accuracy: 0.95363\n",
      "Epoch 29/500, Loss: 0.12054, Accuracy: 0.95743\n",
      "Epoch 30/500, Loss: 0.11675, Accuracy: 0.95953\n",
      "Epoch 31/500, Loss: 0.11542, Accuracy: 0.95713\n",
      "Epoch 32/500, Loss: 0.11401, Accuracy: 0.96082\n",
      "Epoch 33/500, Loss: 0.11222, Accuracy: 0.96018\n",
      "Epoch 34/500, Loss: 0.11000, Accuracy: 0.96076\n",
      "Epoch 35/500, Loss: 0.10787, Accuracy: 0.96082\n",
      "Epoch 36/500, Loss: 0.10734, Accuracy: 0.96269\n",
      "Epoch 37/500, Loss: 0.10463, Accuracy: 0.96117\n",
      "Epoch 38/500, Loss: 0.10305, Accuracy: 0.96029\n",
      "Epoch 39/500, Loss: 0.10199, Accuracy: 0.96351\n",
      "Epoch 40/500, Loss: 0.10034, Accuracy: 0.96199\n",
      "Epoch 41/500, Loss: 0.09900, Accuracy: 0.96316\n",
      "Epoch 42/500, Loss: 0.09742, Accuracy: 0.96444\n",
      "Epoch 43/500, Loss: 0.09614, Accuracy: 0.96304\n",
      "Epoch 44/500, Loss: 0.09466, Accuracy: 0.96538\n",
      "Epoch 45/500, Loss: 0.09283, Accuracy: 0.96608\n",
      "Epoch 46/500, Loss: 0.09166, Accuracy: 0.96561\n",
      "Epoch 47/500, Loss: 0.09028, Accuracy: 0.96351\n",
      "Epoch 48/500, Loss: 0.08975, Accuracy: 0.96608\n",
      "Epoch 49/500, Loss: 0.08795, Accuracy: 0.96620\n",
      "Epoch 50/500, Loss: 0.08662, Accuracy: 0.96456\n",
      "Epoch 51/500, Loss: 0.08543, Accuracy: 0.96789\n",
      "Epoch 52/500, Loss: 0.08550, Accuracy: 0.96708\n",
      "Epoch 53/500, Loss: 0.08357, Accuracy: 0.96784\n",
      "Epoch 54/500, Loss: 0.08215, Accuracy: 0.96772\n",
      "Epoch 55/500, Loss: 0.08135, Accuracy: 0.96912\n",
      "Epoch 56/500, Loss: 0.07956, Accuracy: 0.96942\n",
      "Epoch 57/500, Loss: 0.07944, Accuracy: 0.96649\n",
      "Epoch 58/500, Loss: 0.07817, Accuracy: 0.96667\n",
      "Epoch 59/500, Loss: 0.07653, Accuracy: 0.96544\n",
      "Epoch 60/500, Loss: 0.07630, Accuracy: 0.97041\n",
      "Epoch 61/500, Loss: 0.07566, Accuracy: 0.96988\n",
      "Epoch 62/500, Loss: 0.07423, Accuracy: 0.97140\n",
      "Epoch 63/500, Loss: 0.07363, Accuracy: 0.97187\n",
      "Epoch 64/500, Loss: 0.07299, Accuracy: 0.97082\n",
      "Epoch 65/500, Loss: 0.07150, Accuracy: 0.97216\n",
      "Epoch 66/500, Loss: 0.07061, Accuracy: 0.96906\n",
      "Epoch 67/500, Loss: 0.06971, Accuracy: 0.97158\n",
      "Epoch 68/500, Loss: 0.06836, Accuracy: 0.97170\n",
      "Epoch 69/500, Loss: 0.06773, Accuracy: 0.97339\n",
      "Epoch 70/500, Loss: 0.06672, Accuracy: 0.97193\n",
      "Epoch 71/500, Loss: 0.06610, Accuracy: 0.97135\n",
      "Epoch 72/500, Loss: 0.06567, Accuracy: 0.96895\n",
      "Epoch 73/500, Loss: 0.06439, Accuracy: 0.97257\n",
      "Epoch 74/500, Loss: 0.06341, Accuracy: 0.97304\n",
      "Epoch 75/500, Loss: 0.06219, Accuracy: 0.97415\n",
      "Epoch 76/500, Loss: 0.06214, Accuracy: 0.97327\n",
      "Epoch 77/500, Loss: 0.06094, Accuracy: 0.97509\n",
      "Epoch 78/500, Loss: 0.06051, Accuracy: 0.97216\n",
      "Epoch 79/500, Loss: 0.05964, Accuracy: 0.96784\n",
      "Epoch 80/500, Loss: 0.05888, Accuracy: 0.97392\n",
      "Epoch 81/500, Loss: 0.05812, Accuracy: 0.97480\n",
      "Epoch 82/500, Loss: 0.05660, Accuracy: 0.97485\n",
      "Epoch 83/500, Loss: 0.05636, Accuracy: 0.97287\n",
      "Epoch 84/500, Loss: 0.05591, Accuracy: 0.97649\n",
      "Epoch 85/500, Loss: 0.05472, Accuracy: 0.97620\n",
      "Epoch 86/500, Loss: 0.05371, Accuracy: 0.97591\n",
      "Epoch 87/500, Loss: 0.05375, Accuracy: 0.97743\n",
      "Epoch 88/500, Loss: 0.05276, Accuracy: 0.97140\n",
      "Epoch 89/500, Loss: 0.05155, Accuracy: 0.97649\n",
      "Epoch 90/500, Loss: 0.05152, Accuracy: 0.97608\n",
      "Epoch 91/500, Loss: 0.05086, Accuracy: 0.97573\n",
      "Epoch 92/500, Loss: 0.04949, Accuracy: 0.97567\n",
      "Epoch 93/500, Loss: 0.04902, Accuracy: 0.97702\n",
      "Epoch 94/500, Loss: 0.04867, Accuracy: 0.97538\n",
      "Epoch 95/500, Loss: 0.04770, Accuracy: 0.97468\n",
      "Epoch 96/500, Loss: 0.04699, Accuracy: 0.97287\n",
      "Epoch 97/500, Loss: 0.04640, Accuracy: 0.97784\n",
      "Epoch 98/500, Loss: 0.04602, Accuracy: 0.97795\n",
      "Epoch 99/500, Loss: 0.04574, Accuracy: 0.97561\n",
      "Epoch 100/500, Loss: 0.04503, Accuracy: 0.97345\n",
      "Epoch 101/500, Loss: 0.04386, Accuracy: 0.97830\n",
      "Epoch 102/500, Loss: 0.04424, Accuracy: 0.97883\n",
      "Epoch 103/500, Loss: 0.04268, Accuracy: 0.97784\n",
      "Epoch 104/500, Loss: 0.04183, Accuracy: 0.97795\n",
      "Epoch 105/500, Loss: 0.04189, Accuracy: 0.97807\n",
      "Epoch 106/500, Loss: 0.04143, Accuracy: 0.97871\n",
      "Epoch 107/500, Loss: 0.04092, Accuracy: 0.97713\n",
      "Epoch 108/500, Loss: 0.03972, Accuracy: 0.97977\n",
      "Epoch 109/500, Loss: 0.03900, Accuracy: 0.97871\n",
      "Epoch 110/500, Loss: 0.03920, Accuracy: 0.98058\n",
      "Epoch 111/500, Loss: 0.03757, Accuracy: 0.97772\n",
      "Epoch 112/500, Loss: 0.03791, Accuracy: 0.98029\n",
      "Epoch 113/500, Loss: 0.03731, Accuracy: 0.97936\n",
      "Epoch 114/500, Loss: 0.03632, Accuracy: 0.97906\n",
      "Epoch 115/500, Loss: 0.03584, Accuracy: 0.97474\n",
      "Epoch 116/500, Loss: 0.03544, Accuracy: 0.97848\n",
      "Epoch 117/500, Loss: 0.03488, Accuracy: 0.97936\n",
      "Epoch 118/500, Loss: 0.03395, Accuracy: 0.98029\n",
      "Epoch 119/500, Loss: 0.03399, Accuracy: 0.98018\n",
      "Epoch 120/500, Loss: 0.03297, Accuracy: 0.97596\n",
      "Epoch 121/500, Loss: 0.03281, Accuracy: 0.98018\n",
      "Epoch 122/500, Loss: 0.03258, Accuracy: 0.97830\n",
      "Epoch 123/500, Loss: 0.03110, Accuracy: 0.98099\n",
      "Epoch 124/500, Loss: 0.03181, Accuracy: 0.98199\n",
      "Epoch 125/500, Loss: 0.03151, Accuracy: 0.97649\n",
      "Epoch 126/500, Loss: 0.03010, Accuracy: 0.98047\n",
      "Epoch 127/500, Loss: 0.03001, Accuracy: 0.98058\n",
      "Epoch 128/500, Loss: 0.02999, Accuracy: 0.98058\n",
      "Epoch 129/500, Loss: 0.02894, Accuracy: 0.98070\n",
      "Epoch 130/500, Loss: 0.02841, Accuracy: 0.97854\n",
      "Epoch 131/500, Loss: 0.02795, Accuracy: 0.98187\n",
      "Epoch 132/500, Loss: 0.02766, Accuracy: 0.98105\n",
      "Epoch 133/500, Loss: 0.02700, Accuracy: 0.98070\n",
      "Epoch 134/500, Loss: 0.02638, Accuracy: 0.98158\n",
      "Epoch 135/500, Loss: 0.02593, Accuracy: 0.98129\n",
      "Epoch 136/500, Loss: 0.02537, Accuracy: 0.97912\n",
      "Epoch 137/500, Loss: 0.02588, Accuracy: 0.97643\n",
      "Epoch 138/500, Loss: 0.02494, Accuracy: 0.98140\n",
      "Epoch 139/500, Loss: 0.02543, Accuracy: 0.98058\n",
      "Epoch 140/500, Loss: 0.02437, Accuracy: 0.98152\n",
      "Epoch 141/500, Loss: 0.02371, Accuracy: 0.98240\n",
      "Epoch 142/500, Loss: 0.02394, Accuracy: 0.98000\n",
      "Epoch 143/500, Loss: 0.02281, Accuracy: 0.98181\n",
      "Epoch 144/500, Loss: 0.02223, Accuracy: 0.98175\n",
      "Epoch 145/500, Loss: 0.02199, Accuracy: 0.98152\n",
      "Epoch 146/500, Loss: 0.02202, Accuracy: 0.97737\n",
      "Epoch 147/500, Loss: 0.02177, Accuracy: 0.98339\n",
      "Epoch 148/500, Loss: 0.02051, Accuracy: 0.98357\n",
      "Epoch 149/500, Loss: 0.02085, Accuracy: 0.98263\n",
      "Epoch 150/500, Loss: 0.01994, Accuracy: 0.98327\n",
      "Epoch 151/500, Loss: 0.01968, Accuracy: 0.98339\n",
      "Epoch 152/500, Loss: 0.01988, Accuracy: 0.98105\n",
      "Epoch 153/500, Loss: 0.01992, Accuracy: 0.98345\n",
      "Epoch 154/500, Loss: 0.01939, Accuracy: 0.98018\n",
      "Epoch 155/500, Loss: 0.01796, Accuracy: 0.98287\n",
      "Epoch 156/500, Loss: 0.01840, Accuracy: 0.98345\n",
      "Epoch 157/500, Loss: 0.01783, Accuracy: 0.98205\n",
      "Epoch 158/500, Loss: 0.01733, Accuracy: 0.98082\n",
      "Epoch 159/500, Loss: 0.01689, Accuracy: 0.98322\n",
      "Epoch 160/500, Loss: 0.01759, Accuracy: 0.98287\n",
      "Epoch 161/500, Loss: 0.01691, Accuracy: 0.98175\n",
      "Epoch 162/500, Loss: 0.01653, Accuracy: 0.98099\n",
      "Epoch 163/500, Loss: 0.01666, Accuracy: 0.98257\n",
      "Epoch 164/500, Loss: 0.01581, Accuracy: 0.98117\n",
      "Epoch 165/500, Loss: 0.01520, Accuracy: 0.98281\n",
      "Epoch 166/500, Loss: 0.01528, Accuracy: 0.98135\n",
      "Epoch 167/500, Loss: 0.01547, Accuracy: 0.98187\n",
      "Epoch 168/500, Loss: 0.01420, Accuracy: 0.98398\n",
      "Epoch 169/500, Loss: 0.01483, Accuracy: 0.98263\n",
      "Epoch 170/500, Loss: 0.01297, Accuracy: 0.98374\n",
      "Epoch 171/500, Loss: 0.01359, Accuracy: 0.98222\n",
      "Epoch 172/500, Loss: 0.01401, Accuracy: 0.98398\n",
      "Epoch 173/500, Loss: 0.01337, Accuracy: 0.98327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500, Loss: 0.01224, Accuracy: 0.98386\n",
      "Epoch 175/500, Loss: 0.01258, Accuracy: 0.98129\n",
      "Epoch 176/500, Loss: 0.01235, Accuracy: 0.98392\n",
      "Epoch 177/500, Loss: 0.01220, Accuracy: 0.97678\n",
      "Epoch 178/500, Loss: 0.01210, Accuracy: 0.98333\n",
      "Epoch 179/500, Loss: 0.01118, Accuracy: 0.98269\n",
      "Epoch 180/500, Loss: 0.01098, Accuracy: 0.98427\n",
      "Epoch 181/500, Loss: 0.01142, Accuracy: 0.98111\n",
      "Epoch 182/500, Loss: 0.01045, Accuracy: 0.98363\n",
      "Epoch 183/500, Loss: 0.01089, Accuracy: 0.98275\n",
      "Epoch 184/500, Loss: 0.00985, Accuracy: 0.98199\n",
      "Epoch 185/500, Loss: 0.01031, Accuracy: 0.98193\n",
      "Epoch 186/500, Loss: 0.00965, Accuracy: 0.98368\n",
      "Epoch 187/500, Loss: 0.00959, Accuracy: 0.98351\n",
      "Epoch 188/500, Loss: 0.00955, Accuracy: 0.98298\n",
      "Epoch 189/500, Loss: 0.00920, Accuracy: 0.98298\n",
      "Epoch 190/500, Loss: 0.00846, Accuracy: 0.97947\n",
      "Epoch 191/500, Loss: 0.00983, Accuracy: 0.98363\n",
      "Epoch 192/500, Loss: 0.00766, Accuracy: 0.98322\n",
      "Epoch 193/500, Loss: 0.00921, Accuracy: 0.98357\n",
      "Epoch 194/500, Loss: 0.00712, Accuracy: 0.98246\n",
      "Epoch 195/500, Loss: 0.00908, Accuracy: 0.98538\n",
      "Epoch 196/500, Loss: 0.00787, Accuracy: 0.98363\n",
      "Epoch 197/500, Loss: 0.00838, Accuracy: 0.98164\n",
      "Epoch 198/500, Loss: 0.00816, Accuracy: 0.98444\n",
      "Epoch 199/500, Loss: 0.00774, Accuracy: 0.98281\n",
      "Epoch 200/500, Loss: 0.00641, Accuracy: 0.98228\n",
      "Epoch 201/500, Loss: 0.00791, Accuracy: 0.98316\n",
      "Epoch 202/500, Loss: 0.00774, Accuracy: 0.98029\n",
      "Epoch 203/500, Loss: 0.00613, Accuracy: 0.97971\n",
      "Epoch 204/500, Loss: 0.00653, Accuracy: 0.98444\n",
      "Epoch 205/500, Loss: 0.00699, Accuracy: 0.98240\n",
      "Epoch 206/500, Loss: 0.00540, Accuracy: 0.98351\n",
      "Epoch 207/500, Loss: 0.00680, Accuracy: 0.98480\n",
      "Epoch 208/500, Loss: 0.00633, Accuracy: 0.98099\n",
      "Epoch 209/500, Loss: 0.00605, Accuracy: 0.98404\n",
      "Epoch 210/500, Loss: 0.00532, Accuracy: 0.98345\n",
      "Epoch 211/500, Loss: 0.00555, Accuracy: 0.98287\n",
      "Epoch 212/500, Loss: 0.00574, Accuracy: 0.98322\n",
      "Epoch 213/500, Loss: 0.00577, Accuracy: 0.98515\n",
      "Epoch 214/500, Loss: 0.00561, Accuracy: 0.98450\n",
      "Epoch 215/500, Loss: 0.00478, Accuracy: 0.98427\n",
      "Epoch 216/500, Loss: 0.00497, Accuracy: 0.98404\n",
      "Epoch 217/500, Loss: 0.00536, Accuracy: 0.98199\n",
      "Epoch 218/500, Loss: 0.00485, Accuracy: 0.98392\n",
      "Epoch 219/500, Loss: 0.00550, Accuracy: 0.98240\n",
      "Epoch 220/500, Loss: 0.00414, Accuracy: 0.98462\n",
      "Epoch 221/500, Loss: 0.00390, Accuracy: 0.98333\n",
      "Epoch 222/500, Loss: 0.00604, Accuracy: 0.98433\n",
      "Epoch 223/500, Loss: 0.00395, Accuracy: 0.98363\n",
      "Epoch 224/500, Loss: 0.00305, Accuracy: 0.98415\n",
      "Epoch 225/500, Loss: 0.00523, Accuracy: 0.98444\n",
      "Epoch 226/500, Loss: 0.00359, Accuracy: 0.98199\n",
      "Epoch 227/500, Loss: 0.00465, Accuracy: 0.98468\n",
      "Epoch 228/500, Loss: 0.00435, Accuracy: 0.98462\n",
      "Epoch 229/500, Loss: 0.00382, Accuracy: 0.98298\n",
      "Epoch 230/500, Loss: 0.00287, Accuracy: 0.98497\n",
      "Epoch 231/500, Loss: 0.00580, Accuracy: 0.98515\n",
      "Epoch 232/500, Loss: 0.00287, Accuracy: 0.98468\n",
      "Epoch 233/500, Loss: 0.00305, Accuracy: 0.98386\n",
      "Epoch 234/500, Loss: 0.00403, Accuracy: 0.98368\n",
      "Epoch 235/500, Loss: 0.00263, Accuracy: 0.98304\n",
      "Epoch 236/500, Loss: 0.00342, Accuracy: 0.98433\n",
      "Epoch 237/500, Loss: 0.00455, Accuracy: 0.98462\n",
      "Epoch 238/500, Loss: 0.00267, Accuracy: 0.98433\n",
      "Epoch 239/500, Loss: 0.00335, Accuracy: 0.98404\n",
      "Epoch 240/500, Loss: 0.00430, Accuracy: 0.98515\n",
      "Epoch 241/500, Loss: 0.00238, Accuracy: 0.98345\n",
      "Epoch 242/500, Loss: 0.00287, Accuracy: 0.98544\n",
      "Epoch 243/500, Loss: 0.00218, Accuracy: 0.98339\n",
      "Epoch 244/500, Loss: 0.00359, Accuracy: 0.98497\n",
      "Epoch 245/500, Loss: 0.00337, Accuracy: 0.98257\n",
      "Epoch 246/500, Loss: 0.00203, Accuracy: 0.98544\n",
      "Epoch 247/500, Loss: 0.00399, Accuracy: 0.98140\n",
      "Epoch 248/500, Loss: 0.00210, Accuracy: 0.98444\n",
      "Epoch 249/500, Loss: 0.00286, Accuracy: 0.98509\n",
      "Epoch 250/500, Loss: 0.00329, Accuracy: 0.98421\n",
      "Epoch 251/500, Loss: 0.00145, Accuracy: 0.98509\n",
      "Epoch 252/500, Loss: 0.00430, Accuracy: 0.98515\n",
      "Epoch 253/500, Loss: 0.00075, Accuracy: 0.98573\n",
      "Epoch 254/500, Loss: 0.00367, Accuracy: 0.98573\n",
      "Epoch 255/500, Loss: 0.00225, Accuracy: 0.98433\n",
      "Epoch 256/500, Loss: 0.00302, Accuracy: 0.98257\n",
      "Epoch 257/500, Loss: 0.00094, Accuracy: 0.98322\n",
      "Epoch 258/500, Loss: 0.00450, Accuracy: 0.98450\n",
      "Epoch 259/500, Loss: 0.00076, Accuracy: 0.98520\n",
      "Epoch 260/500, Loss: 0.00302, Accuracy: 0.98111\n",
      "Epoch 261/500, Loss: 0.00262, Accuracy: 0.98123\n",
      "Epoch 262/500, Loss: 0.00092, Accuracy: 0.98468\n",
      "Epoch 263/500, Loss: 0.00368, Accuracy: 0.98398\n",
      "Epoch 264/500, Loss: 0.00143, Accuracy: 0.98526\n",
      "Epoch 265/500, Loss: 0.00233, Accuracy: 0.98491\n",
      "Epoch 266/500, Loss: 0.00068, Accuracy: 0.98567\n",
      "Epoch 267/500, Loss: 0.00450, Accuracy: 0.98404\n",
      "Epoch 268/500, Loss: 0.00136, Accuracy: 0.98596\n",
      "Epoch 269/500, Loss: 0.00051, Accuracy: 0.98398\n",
      "Epoch 270/500, Loss: 0.00395, Accuracy: 0.98520\n",
      "Epoch 271/500, Loss: 0.00046, Accuracy: 0.98503\n",
      "Epoch 272/500, Loss: 0.00427, Accuracy: 0.98550\n",
      "Epoch 273/500, Loss: 0.00172, Accuracy: 0.98374\n",
      "Epoch 274/500, Loss: 0.00078, Accuracy: 0.98561\n",
      "Epoch 275/500, Loss: 0.00390, Accuracy: 0.98491\n",
      "Epoch 276/500, Loss: 0.00062, Accuracy: 0.98591\n",
      "Epoch 277/500, Loss: 0.00491, Accuracy: 0.98456\n",
      "Epoch 278/500, Loss: 0.00063, Accuracy: 0.98520\n",
      "Epoch 279/500, Loss: 0.00211, Accuracy: 0.98205\n",
      "Epoch 280/500, Loss: 0.00231, Accuracy: 0.98561\n",
      "Epoch 281/500, Loss: 0.00225, Accuracy: 0.98480\n",
      "Epoch 282/500, Loss: 0.00046, Accuracy: 0.98520\n",
      "Epoch 283/500, Loss: 0.00336, Accuracy: 0.98363\n",
      "Epoch 284/500, Loss: 0.00058, Accuracy: 0.98544\n",
      "Epoch 285/500, Loss: 0.00039, Accuracy: 0.98585\n",
      "Epoch 286/500, Loss: 0.00454, Accuracy: 0.98561\n",
      "Epoch 287/500, Loss: 0.00099, Accuracy: 0.98023\n",
      "Epoch 288/500, Loss: 0.00289, Accuracy: 0.98567\n",
      "Epoch 289/500, Loss: 0.00038, Accuracy: 0.98573\n",
      "Epoch 290/500, Loss: 0.00376, Accuracy: 0.98491\n",
      "Epoch 291/500, Loss: 0.00040, Accuracy: 0.98579\n",
      "Epoch 292/500, Loss: 0.00358, Accuracy: 0.98146\n",
      "Epoch 293/500, Loss: 0.00118, Accuracy: 0.98556\n",
      "Epoch 294/500, Loss: 0.00032, Accuracy: 0.98550\n",
      "Epoch 295/500, Loss: 0.00417, Accuracy: 0.98485\n",
      "Epoch 296/500, Loss: 0.00059, Accuracy: 0.98614\n",
      "Epoch 297/500, Loss: 0.00030, Accuracy: 0.98556\n",
      "Epoch 298/500, Loss: 0.00356, Accuracy: 0.98480\n",
      "Epoch 299/500, Loss: 0.00051, Accuracy: 0.98585\n",
      "Epoch 300/500, Loss: 0.00028, Accuracy: 0.98573\n",
      "Epoch 301/500, Loss: 0.00831, Accuracy: 0.98462\n",
      "Epoch 302/500, Loss: 0.00049, Accuracy: 0.98532\n",
      "Epoch 303/500, Loss: 0.00031, Accuracy: 0.98573\n",
      "Epoch 304/500, Loss: 0.00024, Accuracy: 0.98556\n",
      "Epoch 305/500, Loss: 0.00365, Accuracy: 0.98532\n",
      "Epoch 306/500, Loss: 0.00026, Accuracy: 0.98556\n",
      "Epoch 307/500, Loss: 0.00268, Accuracy: 0.98310\n",
      "Epoch 308/500, Loss: 0.00064, Accuracy: 0.98538\n",
      "Epoch 309/500, Loss: 0.00023, Accuracy: 0.98585\n",
      "Epoch 310/500, Loss: 0.00228, Accuracy: 0.97936\n",
      "Epoch 311/500, Loss: 0.00122, Accuracy: 0.98596\n",
      "Epoch 312/500, Loss: 0.00022, Accuracy: 0.98591\n",
      "Epoch 313/500, Loss: 0.00230, Accuracy: 0.98228\n",
      "Epoch 314/500, Loss: 0.00073, Accuracy: 0.98532\n",
      "Epoch 315/500, Loss: 0.00021, Accuracy: 0.98561\n",
      "Epoch 316/500, Loss: 0.00368, Accuracy: 0.98579\n",
      "Epoch 317/500, Loss: 0.00030, Accuracy: 0.98585\n",
      "Epoch 318/500, Loss: 0.00018, Accuracy: 0.98591\n",
      "Epoch 319/500, Loss: 0.00465, Accuracy: 0.98450\n",
      "Epoch 320/500, Loss: 0.00047, Accuracy: 0.98544\n",
      "Epoch 321/500, Loss: 0.00021, Accuracy: 0.98573\n",
      "Epoch 322/500, Loss: 0.00016, Accuracy: 0.98614\n",
      "Epoch 323/500, Loss: 0.00015, Accuracy: 0.98550\n",
      "Epoch 324/500, Loss: 0.00406, Accuracy: 0.98596\n",
      "Epoch 325/500, Loss: 0.00026, Accuracy: 0.98608\n",
      "Epoch 326/500, Loss: 0.00016, Accuracy: 0.98591\n",
      "Epoch 327/500, Loss: 0.00311, Accuracy: 0.98602\n",
      "Epoch 328/500, Loss: 0.00021, Accuracy: 0.98602\n",
      "Epoch 329/500, Loss: 0.00015, Accuracy: 0.98550\n",
      "Epoch 330/500, Loss: 0.00345, Accuracy: 0.98509\n",
      "Epoch 331/500, Loss: 0.00026, Accuracy: 0.98602\n",
      "Epoch 332/500, Loss: 0.00016, Accuracy: 0.98585\n",
      "Epoch 333/500, Loss: 0.00174, Accuracy: 0.97953\n",
      "Epoch 334/500, Loss: 0.00229, Accuracy: 0.98637\n",
      "Epoch 335/500, Loss: 0.00019, Accuracy: 0.98591\n",
      "Epoch 336/500, Loss: 0.00104, Accuracy: 0.95661\n",
      "Epoch 337/500, Loss: 0.00225, Accuracy: 0.98573\n",
      "Epoch 338/500, Loss: 0.00017, Accuracy: 0.98585\n",
      "Epoch 339/500, Loss: 0.00013, Accuracy: 0.98567\n",
      "Epoch 340/500, Loss: 0.00361, Accuracy: 0.98275\n",
      "Epoch 341/500, Loss: 0.00049, Accuracy: 0.98526\n",
      "Epoch 342/500, Loss: 0.00017, Accuracy: 0.98573\n",
      "Epoch 343/500, Loss: 0.00013, Accuracy: 0.98561\n",
      "Epoch 344/500, Loss: 0.00468, Accuracy: 0.98550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/500, Loss: 0.00025, Accuracy: 0.98591\n",
      "Epoch 346/500, Loss: 0.00014, Accuracy: 0.98602\n",
      "Epoch 347/500, Loss: 0.00012, Accuracy: 0.98596\n",
      "Epoch 348/500, Loss: 0.00349, Accuracy: 0.97977\n",
      "Epoch 349/500, Loss: 0.00121, Accuracy: 0.98532\n",
      "Epoch 350/500, Loss: 0.00017, Accuracy: 0.98591\n",
      "Epoch 351/500, Loss: 0.00012, Accuracy: 0.98585\n",
      "Epoch 352/500, Loss: 0.00270, Accuracy: 0.98322\n",
      "Epoch 353/500, Loss: 0.00057, Accuracy: 0.98579\n",
      "Epoch 354/500, Loss: 0.00015, Accuracy: 0.98585\n",
      "Epoch 355/500, Loss: 0.00010, Accuracy: 0.98550\n",
      "Epoch 356/500, Loss: 0.00410, Accuracy: 0.98444\n",
      "Epoch 357/500, Loss: 0.00027, Accuracy: 0.98591\n",
      "Epoch 358/500, Loss: 0.00013, Accuracy: 0.98596\n",
      "Epoch 359/500, Loss: 0.00010, Accuracy: 0.98626\n",
      "Epoch 360/500, Loss: 0.00009, Accuracy: 0.98561\n",
      "Epoch 361/500, Loss: 0.00446, Accuracy: 0.98550\n",
      "Epoch 362/500, Loss: 0.00022, Accuracy: 0.98596\n",
      "Epoch 363/500, Loss: 0.00012, Accuracy: 0.98596\n",
      "Epoch 364/500, Loss: 0.00010, Accuracy: 0.98526\n",
      "Epoch 365/500, Loss: 0.00009, Accuracy: 0.98579\n",
      "Epoch 366/500, Loss: 0.00462, Accuracy: 0.98567\n",
      "Epoch 367/500, Loss: 0.00017, Accuracy: 0.98585\n",
      "Epoch 368/500, Loss: 0.00012, Accuracy: 0.98585\n",
      "Epoch 369/500, Loss: 0.00009, Accuracy: 0.98608\n",
      "Epoch 370/500, Loss: 0.00368, Accuracy: 0.98415\n",
      "Epoch 371/500, Loss: 0.00023, Accuracy: 0.98573\n",
      "Epoch 372/500, Loss: 0.00011, Accuracy: 0.98573\n",
      "Epoch 373/500, Loss: 0.00008, Accuracy: 0.98591\n",
      "Epoch 374/500, Loss: 0.00237, Accuracy: 0.98269\n",
      "Epoch 375/500, Loss: 0.00070, Accuracy: 0.98561\n",
      "Epoch 376/500, Loss: 0.00011, Accuracy: 0.98591\n",
      "Epoch 377/500, Loss: 0.00008, Accuracy: 0.98620\n",
      "Epoch 378/500, Loss: 0.00007, Accuracy: 0.98585\n",
      "Epoch 379/500, Loss: 0.00309, Accuracy: 0.98579\n",
      "Epoch 380/500, Loss: 0.00016, Accuracy: 0.98579\n",
      "Epoch 381/500, Loss: 0.00282, Accuracy: 0.98526\n",
      "Epoch 382/500, Loss: 0.00027, Accuracy: 0.98614\n",
      "Epoch 383/500, Loss: 0.00011, Accuracy: 0.98608\n",
      "Epoch 384/500, Loss: 0.00008, Accuracy: 0.98602\n",
      "Epoch 385/500, Loss: 0.00007, Accuracy: 0.98626\n",
      "Epoch 386/500, Loss: 0.00324, Accuracy: 0.98439\n",
      "Epoch 387/500, Loss: 0.00018, Accuracy: 0.98573\n",
      "Epoch 388/500, Loss: 0.00009, Accuracy: 0.98596\n",
      "Epoch 389/500, Loss: 0.00007, Accuracy: 0.98573\n",
      "Epoch 390/500, Loss: 0.00005, Accuracy: 0.98602\n",
      "Epoch 391/500, Loss: 0.00349, Accuracy: 0.98404\n",
      "Epoch 392/500, Loss: 0.00016, Accuracy: 0.98556\n",
      "Epoch 393/500, Loss: 0.00009, Accuracy: 0.98573\n",
      "Epoch 394/500, Loss: 0.00007, Accuracy: 0.98579\n",
      "Epoch 395/500, Loss: 0.00006, Accuracy: 0.98579\n",
      "Epoch 396/500, Loss: 0.00343, Accuracy: 0.98485\n",
      "Epoch 397/500, Loss: 0.00021, Accuracy: 0.98526\n",
      "Epoch 398/500, Loss: 0.00009, Accuracy: 0.98585\n",
      "Epoch 399/500, Loss: 0.00006, Accuracy: 0.98620\n",
      "Epoch 400/500, Loss: 0.00005, Accuracy: 0.98608\n",
      "Epoch 401/500, Loss: 0.00367, Accuracy: 0.98474\n",
      "Epoch 402/500, Loss: 0.00021, Accuracy: 0.98538\n",
      "Epoch 403/500, Loss: 0.00009, Accuracy: 0.98596\n",
      "Epoch 404/500, Loss: 0.00007, Accuracy: 0.98585\n",
      "Epoch 405/500, Loss: 0.00005, Accuracy: 0.98602\n",
      "Epoch 406/500, Loss: 0.00005, Accuracy: 0.98591\n",
      "Epoch 407/500, Loss: 0.00406, Accuracy: 0.98450\n",
      "Epoch 408/500, Loss: 0.00026, Accuracy: 0.98602\n",
      "Epoch 409/500, Loss: 0.00009, Accuracy: 0.98620\n",
      "Epoch 410/500, Loss: 0.00006, Accuracy: 0.98626\n",
      "Epoch 411/500, Loss: 0.00005, Accuracy: 0.98591\n",
      "Epoch 412/500, Loss: 0.00170, Accuracy: 0.97608\n",
      "Epoch 413/500, Loss: 0.00300, Accuracy: 0.98509\n",
      "Epoch 414/500, Loss: 0.00012, Accuracy: 0.98544\n",
      "Epoch 415/500, Loss: 0.00008, Accuracy: 0.98550\n",
      "Epoch 416/500, Loss: 0.00006, Accuracy: 0.98567\n",
      "Epoch 417/500, Loss: 0.00004, Accuracy: 0.98573\n",
      "Epoch 418/500, Loss: 0.00090, Accuracy: 0.97310\n",
      "Epoch 419/500, Loss: 0.00333, Accuracy: 0.98515\n",
      "Epoch 420/500, Loss: 0.00010, Accuracy: 0.98544\n",
      "Epoch 421/500, Loss: 0.00007, Accuracy: 0.98561\n",
      "Epoch 422/500, Loss: 0.00005, Accuracy: 0.98509\n",
      "Epoch 423/500, Loss: 0.00004, Accuracy: 0.98573\n",
      "Epoch 424/500, Loss: 0.00378, Accuracy: 0.98316\n",
      "Epoch 425/500, Loss: 0.00050, Accuracy: 0.98550\n",
      "Epoch 426/500, Loss: 0.00010, Accuracy: 0.98538\n",
      "Epoch 427/500, Loss: 0.00006, Accuracy: 0.98497\n",
      "Epoch 428/500, Loss: 0.00005, Accuracy: 0.98573\n",
      "Epoch 429/500, Loss: 0.00004, Accuracy: 0.98579\n",
      "Epoch 430/500, Loss: 0.00703, Accuracy: 0.98485\n",
      "Epoch 431/500, Loss: 0.00015, Accuracy: 0.98567\n",
      "Epoch 432/500, Loss: 0.00008, Accuracy: 0.98579\n",
      "Epoch 433/500, Loss: 0.00005, Accuracy: 0.98573\n",
      "Epoch 434/500, Loss: 0.00004, Accuracy: 0.98614\n",
      "Epoch 435/500, Loss: 0.00003, Accuracy: 0.98626\n",
      "Epoch 436/500, Loss: 0.00419, Accuracy: 0.98398\n",
      "Epoch 437/500, Loss: 0.00070, Accuracy: 0.98544\n",
      "Epoch 438/500, Loss: 0.00008, Accuracy: 0.98602\n",
      "Epoch 439/500, Loss: 0.00006, Accuracy: 0.98591\n",
      "Epoch 440/500, Loss: 0.00004, Accuracy: 0.98526\n",
      "Epoch 441/500, Loss: 0.00003, Accuracy: 0.98585\n",
      "Epoch 442/500, Loss: 0.00003, Accuracy: 0.98591\n",
      "Epoch 443/500, Loss: 0.00420, Accuracy: 0.98515\n",
      "Epoch 444/500, Loss: 0.00019, Accuracy: 0.98550\n",
      "Epoch 445/500, Loss: 0.00007, Accuracy: 0.98602\n",
      "Epoch 446/500, Loss: 0.00005, Accuracy: 0.98620\n",
      "Epoch 447/500, Loss: 0.00004, Accuracy: 0.98602\n",
      "Epoch 448/500, Loss: 0.00003, Accuracy: 0.98591\n",
      "Epoch 449/500, Loss: 0.00013, Accuracy: 0.98058\n",
      "Epoch 450/500, Loss: 0.00415, Accuracy: 0.98585\n",
      "Epoch 451/500, Loss: 0.00006, Accuracy: 0.98573\n",
      "Epoch 452/500, Loss: 0.00004, Accuracy: 0.98579\n",
      "Epoch 453/500, Loss: 0.00003, Accuracy: 0.98596\n",
      "Epoch 454/500, Loss: 0.00003, Accuracy: 0.98515\n",
      "Epoch 455/500, Loss: 0.00003, Accuracy: 0.98591\n",
      "Epoch 456/500, Loss: 0.00124, Accuracy: 0.97965\n",
      "Epoch 457/500, Loss: 0.00218, Accuracy: 0.98526\n",
      "Epoch 458/500, Loss: 0.00007, Accuracy: 0.98532\n",
      "Epoch 459/500, Loss: 0.00004, Accuracy: 0.98532\n",
      "Epoch 460/500, Loss: 0.00003, Accuracy: 0.98538\n",
      "Epoch 461/500, Loss: 0.00002, Accuracy: 0.98573\n",
      "Epoch 462/500, Loss: 0.00002, Accuracy: 0.98579\n",
      "Epoch 463/500, Loss: 0.00217, Accuracy: 0.98058\n",
      "Epoch 464/500, Loss: 0.00100, Accuracy: 0.98567\n",
      "Epoch 465/500, Loss: 0.00006, Accuracy: 0.98579\n",
      "Epoch 466/500, Loss: 0.00004, Accuracy: 0.98567\n",
      "Epoch 467/500, Loss: 0.00003, Accuracy: 0.98585\n",
      "Epoch 468/500, Loss: 0.00002, Accuracy: 0.98585\n",
      "Epoch 469/500, Loss: 0.00002, Accuracy: 0.98579\n",
      "Epoch 470/500, Loss: 0.00337, Accuracy: 0.98439\n",
      "Epoch 471/500, Loss: 0.00019, Accuracy: 0.98520\n",
      "Epoch 472/500, Loss: 0.00006, Accuracy: 0.98573\n",
      "Epoch 473/500, Loss: 0.00004, Accuracy: 0.98585\n",
      "Epoch 474/500, Loss: 0.00003, Accuracy: 0.98561\n",
      "Epoch 475/500, Loss: 0.00002, Accuracy: 0.98602\n",
      "Epoch 476/500, Loss: 0.00002, Accuracy: 0.98614\n",
      "Epoch 477/500, Loss: 0.00349, Accuracy: 0.98415\n",
      "Epoch 478/500, Loss: 0.00022, Accuracy: 0.98532\n",
      "Epoch 479/500, Loss: 0.00006, Accuracy: 0.98573\n",
      "Epoch 480/500, Loss: 0.00003, Accuracy: 0.98550\n",
      "Epoch 481/500, Loss: 0.00003, Accuracy: 0.98573\n",
      "Epoch 482/500, Loss: 0.00002, Accuracy: 0.98591\n",
      "Epoch 483/500, Loss: 0.00002, Accuracy: 0.98626\n",
      "Epoch 484/500, Loss: 0.00001, Accuracy: 0.98585\n",
      "Epoch 485/500, Loss: 0.00427, Accuracy: 0.98269\n",
      "Epoch 486/500, Loss: 0.00056, Accuracy: 0.98526\n",
      "Epoch 487/500, Loss: 0.00005, Accuracy: 0.98567\n",
      "Epoch 488/500, Loss: 0.00003, Accuracy: 0.98585\n",
      "Epoch 489/500, Loss: 0.00002, Accuracy: 0.98596\n",
      "Epoch 490/500, Loss: 0.00002, Accuracy: 0.98602\n",
      "Epoch 491/500, Loss: 0.00001, Accuracy: 0.98591\n",
      "Epoch 492/500, Loss: 0.00001, Accuracy: 0.98608\n",
      "Epoch 493/500, Loss: 0.00295, Accuracy: 0.98468\n",
      "Epoch 494/500, Loss: 0.00013, Accuracy: 0.98544\n",
      "Epoch 495/500, Loss: 0.00003, Accuracy: 0.98573\n",
      "Epoch 496/500, Loss: 0.00002, Accuracy: 0.98585\n",
      "Epoch 497/500, Loss: 0.00002, Accuracy: 0.98596\n",
      "Epoch 498/500, Loss: 0.00002, Accuracy: 0.98608\n",
      "Epoch 499/500, Loss: 0.00001, Accuracy: 0.98632\n",
      "Epoch 500/500, Loss: 0.00001, Accuracy: 0.98608\n",
      "Best Accuracy: 0.986374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "num_epochs = 500\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float().to(device)\n",
    "y_train = torch.from_numpy(y_train).long().to(device)\n",
    "y_test = torch.from_numpy(y_test).long().to(device)\n",
    "\n",
    "# Create the DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = AudioCNN().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    # deep copy the model\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.5f}, Accuracy: {epoch_acc:.5f}')\n",
    "\n",
    "print('Best Accuracy: {:5f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77616d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf88487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1db67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa530bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73832c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a7a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d24fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a63ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce020e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1131e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c972e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d03785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b9af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
